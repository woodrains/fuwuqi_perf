项目代码整理说明（LLMulator_1010）

目标
- 对原始项目 /root/llmulator 进行取舍与整理，保留复现论文所必需的代码路径与脚本，移除（不复制）体量大、用途不明或实验性质强的文件，形成一个干净的、可运行的复现工程。
- 核心算法代码不在原目录修改；如需调整，均复制到本目录 src/ 下再做最小改动。

保留内容（必要）
- 数据集读取与特征抽取：从 train.py 复制的 A/B/C 矩阵与 loop 特征加工逻辑，封装在 `src/data/json_dataset.py`。
- 模型主体（Transformer‑H / HardwarePerformancePredictor）：从 train.py 复制，不改动算法逻辑，放在 `src/models/hardware_predictor.py`。
- 训练与评估：
  - `src/train/train_hardware.py`：拷贝并封装原训练流程，默认 epoch 稍大，便于稳定复现；日志写入 logs。
  - `src/train/sft_digit_ce.py`：基于 sfttrain.py 的数字首位分类 SFT；评估阶段加入 pass@5 采样。
- 动态校准（DPO）：`src/dpo/train_dpo.py` 基于 llmevaluator/dpo.py，支持 LoRA 低开销微调。
- 数值生成评测：`src/eval/eval_pass5_llama.py` 基于 llmevaluator/inference.py，显式实现 pass@5 与 MAPE。

移除/不复制（非必要或过大）
- 大型数据（dataset/hls_dataset/llm_dataset 等）、中间产物（logs/HLS_output/obj_dir 等）。本工程通过路径引用原数据。
- 零散的原型/实验脚本（如 train_llama.py 等）及硬件合成脚本（与论文复现主线无关）。

数据与路径
- 使用 `configs/paths.yaml` 统一配置：
  - 训练/测试数据目录默认指向本工程 `./data/structured/hybrid/{train,test}`；
  - LLM 评测数据默认使用本工程 `./data/llm/{train,test}/profiledataset.json`。
- 已复制必要的已处理数据到本工程（./data），可脱离原仓库独立运行；如需自定义数据路径可在 paths.yaml 中修改。

评估指标
- 按论文：MAPE/MSE；数值生成路径启用 pass@5 采样（每条样本生成 5 次，使用中位数汇总，并统计 10% 误差内的 pass@5 命中率）。

动态微调
- 提供 DPO（LoRA）脚本，支持对“与测试程序近似”的样本进行轻量动态校准，缓解灾难性遗忘。

缺失项（需用户自备）
- 基座 LLM 权重（论文用 LLaMA‑3.x）；需自备合法下载路径或本地模型目录。
- 原 inference 依赖的 llama_recipes 工具；当前复现路径直接使用 Transformers，不再依赖该工具。
- 多卡算力（论文为 8×A100 80GB）；若算力不足，性能与时延可能有差异。

运行指南
- 创建并激活 conda 环境 `llmulator`：`conda env create -f environment.yml && conda activate llmulator`
- 训练（SFT + 硬件预测器）：`bash scripts/train_all.sh`
- 单独评估（pass@5）：`bash scripts/eval.sh`
