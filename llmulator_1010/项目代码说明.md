# 项目代码说明（`llmulator_1010`）

> 本文档面向“读代码 + 复现论文主链路”的需求，说明本工程的目录结构、关键模块、训练/评估流程，以及论文/项目的核心创新点在代码层面的落点：**数值建模静态预测 + 动态预测校准 + 渐进式数据集合成器**。
>
> 说明范围仅覆盖本目录 `llmulator_1010/`（一个“可运行的精简复现工程”）。原始仓库中被裁剪/未复制的实验代码与大型数据不在本文档范围内。

---

## 1. 项目目标与整体流程

### 1.1 这个工程解决什么问题？

LLMulator 论文/项目关注的问题是：**对“数据流加速器/编译指令/循环映射”这类带强离散结构的程序输入，做准确且可泛化的性能预测**（如 delay/power/area 或某个 profile 值），并且要能在**测试分布变化**时仍然稳健。

本工程 `llmulator_1010` 是一个“干净、最小、可运行”的复现目录：

- 保留复现主算法链路所需的核心代码与脚本：数据读取、静态预测模型训练、DPO 动态校准、pass@5 评估、可选的 Transformer‑H 结构化预测器。
- 通过 `configs/paths.yaml` 把数据/模型路径集中配置，默认使用 `./data` 下的本地已处理数据，不依赖外部原仓库的数据布局。

### 1.2 复现主链路（推荐按顺序跑）

1) **静态预测（数值建模）**：对“输入 → 数值输出”做监督学习（本工程使用 LoRA + 简化版“首数字 CE”）。
2) **动态预测校准（DPO）**：在接近测试分布的数据上做轻量偏好微调（LoRA + TRL DPO）。
3) **评估（pass@5 + MAPE）**：对同一提示采样 K 次，取中位数做 MAPE；并统计 pass@K（10% 阈值）作为 sanity check。

可选分支：

- **Transformer‑H / HardwarePerformancePredictor**：对结构化特征（A/B/C 矩阵 + loop 统计 + 指令映射）做回归式预测（delay/power/area）。

---

## 2. 核心创新点（论文思想 → 本工程代码落点）

> 你关心的三个关键词：**数值建模静态预测 + 动态预测校准 + 渐进式数据集合成器**。下面按“思想/目标 → 本工程落点 → 现状与差异”说明。

### 2.1 数值建模静态预测（Static Prediction via Numeric Modeling）

**思想/目标（论文视角）**

- 把“性能数值”当作可生成的 token 序列（数字/小数点/换行等），让 LLM 用语言建模方式输出数值。
- 通过“按位/按数字”的离散建模，缓解纯回归在极值和长尾上的不稳定，并可配合 pass@K 降低采样噪声。

**本工程的代码落点**

- 训练（SFT，LoRA）：`src/train/sft_digit_ce.py`
  - `TextDigitModel`：封装 LoRA‑CausalLM，并构造 0~9 的 digit token id。
  - `float_to_digit_label()`：把标注值映射为 0~9 的类别（本工程实现为 `round(x*9)` 的“首数字/首桶 CE”）。
  - `train_with_ce()`：按 batch（默认 1）训练，loss 为最后一个 token 的 CE。
  - `evaluate_pass5()`：对每条样本采样 5 次，若任一次首 digit 命中则算 pass@5。
- 推理/评估（pass@K + MAPE）：`src/eval/eval_pass5_llama.py`
  - 输入提示固定为：`instruction + "\nProfile: "`
  - `predict_k()`：采样 K 次生成。
  - `extract_number()`：用正则从输出中抽取 `Profile: <number>`。
  - 聚合：对每样本预测取 `median(preds_valid)`，计算 MAPE；并统计 `pass@K within 10%`。

**现状与差异（务必注意）**

- 本工程的 SFT 实现是“**首数字 CE**”（更像一个简化基线），并非论文提到的完整“渐进数值编码/逐位建模”。`docs/REPRODUCTION_GUIDE/STATUS.md` 也明确记录了这一点。
- 评估脚本使用的测试集是 `data/llm/test/profiledataset.json`（含 `instruction/output` 且输出形如 `Profile: 1.872`），而 `sft_digit_ce.py` 的训练数据来自 `data/structured/.../*.json` 读出的 `str(data)` 与归一化 `profile theory value`。这两条数据管线在“提示/标签尺度/格式”上可能并不完全一致——这也是当前复现与论文指标存在差距的原因之一。

### 2.2 动态预测校准（Dynamic Prediction Calibration）

**思想/目标（论文视角）**

- 当测试程序/映射/硬件配置分布变化时，静态模型可能偏移。
- 通过“输入驱动”的轻量微调（LoRA），利用与测试样本**相似**的少量数据在推理前完成校准，减少分布外误差，并避免灾难性遗忘。

**本工程的代码落点**

- DPO 训练入口：`src/dpo/train_dpo.py`
  - 使用 TRL 的 `DPOTrainer`，以 JSON 数据集（`prompt/chosen/rejected`）做偏好学习。
  - LoRA 配置：`target_modules=["q_proj","v_proj"]`，低成本快速校准。
  - 输出：`configs/paths.yaml` 的 `models.dpo_out_dir`（默认 `./models/dpo_lora`）。
- 训练脚本：`scripts/run_dpo.sh`
  - 默认数据：`data/llmevaluator/data_dpo.json`（本工程内置 28 对偏好样本，可扩充）。

**使用方式（与评估联动）**

- `scripts/eval.sh` 会优先加载 `./models/dpo_lora`，否则回退到 `./models/sft_lora`。
- 评估时通过 `--peft_model` 将 LoRA adapter 挂到基座模型上，从而实现“动态校准后的推理”。

### 2.3 渐进式数据集合成器（Progressive Dataset Synthesizer）

**思想/目标（论文视角）**

- 系统性扩充训练数据覆盖面：软件/硬件、多层 dataflow、存储参数、循环映射原语等。
- 引入 AST‑based 样本与 LLM‑generated programs，增强“跨程序/跨输入/跨配置”的泛化能力。

**本工程的“落点”与边界**

- 本目录中**不包含**“数据集合成器/生成器”的实现代码；相应能力以“合成后的数据产物”的形式体现在 `./data/`：
  - `data/structured/...`：结构化 JSON（含 A/B/C 矩阵、loop 统计、指令等），用于 Transformer‑H/结构化训练管线。
  - `data/llm/.../profiledataset.json`：用于 LLM 提示‑输出式训练/评估的数据（`instruction/output`）。
  - `data/llmevaluator/*.json`：用于动态校准与评测辅助的数据（如 `data_dpo.json`）。
- 换句话说：**本工程复现的是“使用渐进式合成数据训练/校准/评估”的链路**；合成器本体属于上游数据工程（论文贡献之一），在该精简工程中以数据集形式被“冻结”下来。

---

## 3. 目录结构（从入口到核心实现）

```
llmulator_1010/
  configs/
    paths.yaml                  # 统一配置数据/模型路径
  data/                         # 本地已处理数据（精简复现可独立运行）
  docs/REPRODUCTION_GUIDE/      # 复现说明（环境/数据/训练/评估/状态/排障）
  models/
    sft_lora/                   # SFT LoRA 产物（示例/可复用）
    dpo_lora/                   # DPO LoRA 产物（示例/可复用）
  scripts/
    train_sft.sh                # 静态预测：SFT（首数字 CE）
    run_dpo.sh                  # 动态校准：DPO
    eval.sh                     # pass@5 + MAPE 评估
    train_hardware.sh           # 可选：Transformer‑H 结构化预测器训练
    train_all.sh                # 一键：SFT + Transformer‑H
  src/
    utils/path_resolver.py      # 基座模型路径解析（env > cfg > candidates > fallback）
    data/json_dataset.py        # 结构化 JSON 解析：特征 + A/B/C 矩阵 → 张量
    models/hardware_predictor.py# Transformer‑H / HardwarePerformancePredictor
    train/sft_digit_ce.py       # LoRA SFT（首数字 CE）+ pass@5（首 digit）
    train/train_hardware.py     # Transformer‑H 训练与评估（MSE）
    dpo/train_dpo.py            # TRL DPO 动态校准（LoRA）
    eval/eval_pass5_llama.py    # LLM 推理评估：pass@K + median-of-K + MAPE
```

---

## 4. 配置与路径解析（保证可移植、可复现）

### 4.1 `configs/paths.yaml`：统一入口

- `data.*`：结构化数据目录、LLM 文本数据路径。
- `models.*`：SFT/DPO/硬件预测器的输出目录。
- `llm.*`：基座模型的路径/候选路径/兜底 HF 模型名，以及是否用 bf16。

### 4.2 `src/utils/path_resolver.py`：避免硬编码

`get_base_model_path(cfg)` 的优先级：

1) 环境变量 `LLMULATOR_BASE_MODEL`
2) `cfg.llm.base_model`（可为本地路径或 HF id）
3) `cfg.llm.candidate_paths` 中第一个存在的路径
4) `cfg.llm.fallback_model`（默认 TinyLlama，用于调试）

脚本层面（`scripts/*.sh`）支持用 `.base_model_path` 文件快速注入：

- `scripts/eval.sh` / `scripts/train_sft.sh` / `scripts/run_dpo.sh` / `scripts/train_hardware.sh`：若存在 `./.base_model_path`，则导出到 `LLMULATOR_BASE_MODEL`。

---

## 5. 数据格式与数据加载（模型是否能学到“结构”取决于这里）

### 5.1 结构化 JSON（`data/structured/.../*.json`）

这类样本面向 Transformer‑H 与“把结构化输入 stringify 给 LLM”的训练方式，典型字段包括：

- `Code Type`：如 `HLS` / `OpenACC` / `C`
- `A Matrix`：变量 ↔ 存储映射 + loop pragma 相关条目
- `B Matrix`：变量 ↔ 硬件映射 + loop pragma 相关条目
- `Group i Loop Level j`：每层循环的统计特征（range、op counts、directive、C Matrix 等）
- `profile theory value` / `profile power value` / `profile area value`
- `loop code`：程序片段（可选）

加载/特征化逻辑在 `src/data/json_dataset.py`：

- `extract_features()`：把每层 loop 的统计特征映射为定长张量（最多 64 层，每层 8 维）。
- `process_A_matrix()` / `process_B_matrix()`：对离散字符串做在线编码（`encode_string`），生成变量‑存储/变量‑硬件/pragma 映射张量。
- `process_C_matrix()`：收集每层 loop 的 `C Matrix`（本数据集中常为标量/float），最终变成浮点张量。
- `JsonDataset.__getitem__()`：返回一个 tuple，供训练脚本按固定顺序解包：
  - `hardware_embedding, code_embedding, A_var_mem, A_loop_pragma, B_var_hw, B_loop_pragma, C_matrix, profile_value, inputs(str(data)), codetype, power, area, name`

### 5.2 LLM 文本数据（`data/llm/*/profiledataset.json`）

评估脚本 `src/eval/eval_pass5_llama.py` 使用该格式，每条样本至少包含：

- `instruction`：提示（通常含程序/设计描述）
- `output`：必须能匹配 `Profile: <number>`（评估用正则抽取）
- `input`：可为空/辅助字段

### 5.3 DPO 偏好数据（`data/llmevaluator/data_dpo.json`）

`src/dpo/train_dpo.py` 期望每条样本为：

- `prompt`：输入提示（通常是程序/描述）
- `chosen`：偏好更优的输出（完整字符串）
- `rejected`：偏好较差的输出（完整字符串）

> 扩充 DPO 数据时，关键是让 `prompt` 的分布尽量贴近真实测试提示；并且 `chosen/rejected` 的差异要能表达“更接近真实 profile/更可用的输出格式”。

---

## 6. 关键模块逐个解释（读代码时从哪里开始）

### 6.1 静态预测：LoRA SFT（首数字 CE）

文件：`src/train/sft_digit_ce.py`

核心点：

- **训练目标不是回归**，而是把标注映射成 0~9 的离散类别，在 LM 的“下一 token”位置做 CE。
- `TextDigitModel.forward()`：只取最后一个位置的 logits，计算 digit‑CE。
- `evaluate_pass5()`：对同一输入采样 5 次，任意一次命中即 pass@5（首 digit）。

你可以把它理解为论文“数值 token 建模”的**极简版本**：先把“数值预测”变成“数字类别预测”，建立可采样、可集成（pass@K）的预测框架。

### 6.2 动态校准：LoRA DPO

文件：`src/dpo/train_dpo.py`

核心点：

- 用 TRL 的 `DPOTrainer` 做偏好优化：在不训练 ref_model 的情况下，以 LoRA adapter 快速对齐“更优输出”。
- 这是“动态预测校准”的实现载体：同一个基座模型，在不改变主干参数的前提下，用少量新数据校准到更贴近测试分布的行为。

### 6.3 评估：pass@K + median-of-K + MAPE

文件：`src/eval/eval_pass5_llama.py`

核心点：

- `predict_k()`：采样 K 次；生成策略为 `top_p=0.95, temperature=0.8`（可调）。
- 用 `median(preds_valid)` 聚合，减少采样波动。
- `extract_number()` 只认 `Profile:` 这一输出协议；如果你改了提示/输出模板，评估也要同步改正则。

### 6.4 结构化静态预测：Transformer‑H / HardwarePerformancePredictor（可选）

文件：`src/models/hardware_predictor.py`、`src/train/train_hardware.py`

核心点：

- 输入由三部分拼接：A/B 映射（mem/compute 两路）+ loop 统计特征（`extract_features`）+ 文本 token embedding（`tokenizer.encode(str(inputs))`）。
- 采用两路 `TransformerDecoder` 分别建模 memory/computation 特征，最后用若干线性头与 `sigmoid` 组合输出：
  - delay `D`
  - power `P`
  - area `A`
- 训练脚本默认 MSE，并支持只训 delay（`only_delay`）。

这条路径可视为论文中“专门的硬件性能预测器”的结构化实现（与 LLM 数值生成路径互补）。

---

## 7. 复现命令（最常用）

> 具体细节可对照 `docs/REPRODUCTION_GUIDE/`，本文只给最短路径。

### 7.1 环境

```
conda env create -f environment.yml
conda activate llmulator
```

### 7.2 指定基座模型（推荐）

```
echo "/your/local/Llama-3.2-1B-Instruct" > .base_model_path
# 或：export LLMULATOR_BASE_MODEL=/your/local/Llama-3.2-1B-Instruct
```

### 7.3 训练 + 评估

```
# 静态预测（SFT）
EPOCHS=15 bash scripts/train_sft.sh

# 动态校准（DPO）
EPOCHS=3 bash scripts/run_dpo.sh

# 评估（优先用 dpo_lora，其次 sft_lora）
bash scripts/eval.sh
```

### 7.4 可选：训练结构化硬件预测器

```
bash scripts/train_hardware.sh
```

---

## 8. 常见问题与扩展建议（与三大创新点直接相关）

### 8.1 为什么要 pass@K？

因为数值输出是“采样生成”的，单次生成受温度/随机性影响较大。`median-of-K` 是廉价且有效的稳定器；论文也用 pass@5 做更稳健的报告。

### 8.2 如何把“首数字 CE”升级为论文的“渐进数值编码”？

本工程已经提供了：

- LoRA‑CausalLM 的训练骨架（`TextDigitModel`）
- pass@K 的推理与评估骨架（`eval_pass5_llama.py`）

缺的是“数值 → 逐位 token label”的编码/解码协议与 loss 设计。实现方式通常包括：

- 将目标数值格式化成固定模板（如定点/科学计数法/位宽对齐）。
- 对每一位数字（含小数点/符号位）做分类 loss（多位置 CE），并在推理时对输出空间做约束（只允许 digit/`.`/`\n` 等）。

### 8.3 如何提升动态校准效果？

- 扩充 `data/llmevaluator/data_dpo.json`（让 prompt 更贴近测试分布；chosen/rejected 更能表达“预测更准/格式更符合协议”）。
- 增加 epochs 或有效 batch（`train_dpo.py` 的 `per_device_train_batch_size` + `gradient_accumulation_steps` 可调）。

### 8.4 渐进式数据集合成器在哪里？

不在本目录代码中；本目录只保留其“产物数据”以支持复现训练/评估。

如果你要把合成器接回来，推荐的接口方式是：

1) 合成/处理后的数据落到 `data/structured/...` 与 `data/llm/...` 的同格式文件；
2) 只需要改 `configs/paths.yaml`，无需动训练代码。

---

## 9. 快速“读代码”路线图（建议从这几个文件开始）

1) `README.md`、`CODE_ORGANIZATION.md`、`docs/REPRODUCTION_GUIDE/README.md`：先理解保留了哪些主链路。
2) `configs/paths.yaml` + `src/utils/path_resolver.py`：确认模型/数据路径如何解析。
3) 静态预测：`src/train/sft_digit_ce.py` → `src/eval/eval_pass5_llama.py`
4) 动态校准：`src/dpo/train_dpo.py`（以及 `data/llmevaluator/data_dpo.json` 格式）
5) 结构化预测器（可选）：`src/data/json_dataset.py` → `src/models/hardware_predictor.py` → `src/train/train_hardware.py`

